{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Email_summarizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sAE81UhlSHJ"
      },
      "source": [
        "import os\n",
        "import struct\n",
        "from string import punctuation\n",
        "from collections import defaultdict\n",
        "from heapq import nlargest\n",
        "import operator\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVr0yDO-lcJb",
        "outputId": "286ec8d8-dd11-4de4-af7c-be0fbf53c6da"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFac_EMhlinu"
      },
      "source": [
        "STOP_WORDS = set(stopwords.words('english') + list(punctuation))\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    stems = []\n",
        "    for item in tokens:\n",
        "        stems.append(WordNetLemmatizer().lemmatize(item))\n",
        "\n",
        "    stems = [word.lower().strip() for word in stems]\n",
        "    return stems\n",
        "\n",
        "def get_frequencies(text):\n",
        "     \n",
        "    tfidf = TfidfVectorizer(tokenize(text),STOP_WORDS)\n",
        "    tfs = tfidf.fit_transform([text])\n",
        "\n",
        "    freqs = {}\n",
        "    feature_names = tfidf.get_feature_names()\n",
        "    for col in tfs.nonzero()[1]:\n",
        "        freqs[feature_names[col]] = tfs[0, col]\n",
        "\n",
        "    return freqs\n",
        "\n",
        "def generate_summary(text,top_n_sentences):\n",
        "      \n",
        "    freqs = get_frequencies(text)\n",
        "    sentences = sent_tokenize(text)\n",
        "    important_sentences = defaultdict(int)\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        for token in word_tokenize(sentence.lower()):\n",
        "            if token in freqs:\n",
        "                important_sentences[i] += freqs[token]\n",
        "\n",
        "        # Choose 20% of the text to show\n",
        "    number_sentences = int(len(sentences) * 0.2)\n",
        "\n",
        "        # Create an index with the most important sentences\n",
        "    index_important_sentences = nlargest(number_sentences,\n",
        "                                             important_sentences,\n",
        "                                             important_sentences.get)\n",
        "\n",
        "        # Sort frequencies\n",
        "    sorted_freqs = sorted(freqs.items(), key=operator.itemgetter(1), reverse=True)\n",
        "\n",
        "        # Create summary\n",
        "    summarised_text = []\n",
        "    ctr = 0\n",
        "    for i in sorted(index_important_sentences):\n",
        "        summarised_text.append(sentences[i])\n",
        "        ctr = ctr + 1\n",
        "        if top_n_sentences == ctr:\n",
        "            break\n",
        "\n",
        "    return summarised_text, sorted_freqs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpB2GiA7mVHm"
      },
      "source": [
        "email_1 = '''\n",
        "Hi Nicole,\n",
        "\n",
        "Thank you for keeping me updated on this issue. I'm happy to hear that the issue got resolved after all. \n",
        "You can now use the app in its full functionality again. \n",
        "Also many thanks for your suggestions. We hope to improve this feature in the future. \n",
        "\n",
        "In case you experience any further problems with the app, please don't hesitate to contact me again.\n",
        "\n",
        "Best regards,\n",
        "\n",
        "John D.\n",
        "Customer Support\n",
        "\n",
        "0000 Sunshine Parkway\n",
        "Mountain View, CA\n",
        "United States'''\n",
        "email_2 = '''\n",
        "Dear Jennifer,\n",
        "\n",
        "Thanks for the advertisement you sent me about the Fashion Show. I think it will be a fantastic event and I want to be there, but before I come to Paris I need to know a little more about train timetables and the show. Could you give me more information?\n",
        "I’m trying to decide which train to take. I think the best option is to take the last one from Berlin, but it doesn’t arrive in Paris until about ten o’clock. Will that be OK, or is it too late for you?\n",
        "I’ve never been to a fashion show before. I’ve never been to Paris, either, so I need your advice. What kind of clothes do you think I should wear? And what’s the weather like at the moment? Is it warm or rather cold? Do I need to bring some warm clothes? What about rain? What are the weather forecasts? Do they say it is going to rain within the next 2 days or not? I don’t know if I am able to pack into my bag, it isn’t too big. Maybe I will take 2 of them.\n",
        "By the way, what shall we do on Sunday? How about going for a walk in the park, or going on a river cruise? Or maybe you’ve got some other, better ideas? Tell me if something comes to your mind.\n",
        "Anyway, I can’t wait to see you. I’m looking forward to hearing from you. Answer me as soon as it’s possible.\n",
        "\n",
        "Cheers,\n",
        "Meghan''' \n",
        "\n",
        "email_3 = '''\n",
        "Hello Michael,\n",
        "\n",
        "Thank you for your e mail I received a week ago. I’m sorry that I didn’t reply to your letter sooner, but I’m spending my time now in a summer house where Internet connection is very weak.\n",
        "Anyway, it’s a great place to relax and take a break after a hard year in our school.\n",
        "I don’t watch TV here nor do I use a mobile phone or a computer, so I have much more time than on my hands than I do usually. I feel healthier and I’m tanned. I swim a lot in a local lake, ride a bike and play football with local people. I’ve made many new friends.\n",
        "I wish you were here. Would you like to come along the next year? I bet you’ll be satisfied.\n",
        "Answer me.\n",
        "\n",
        "Thanks, \n",
        "P. G.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUnJdrnxwBDp"
      },
      "source": [
        "#!pip3 install talon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHV63yxJv6TQ",
        "outputId": "2531c6d1-d9f8-4a6f-e5de-4ca2a795e3f2"
      },
      "source": [
        "from talon.signature.bruteforce import extract_signature\n",
        "\n",
        "def preprocess(email):\n",
        "    email, _ = extract_signature(email)\n",
        "    \n",
        "    lines = email.split('\\n')\n",
        "\n",
        "    for i in reversed(range(len(lines))):\n",
        "        lines[i] = lines[i].strip()\n",
        "        if lines[i] == '':\n",
        "          lines.pop(i)\n",
        "    email = '\\n'.join(lines)\n",
        "    email = extract_salutation(email)\n",
        "    return email"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKCr3KCOwO84",
        "outputId": "77d21897-96fd-48cc-a843-a9fa7dd22a09"
      },
      "source": [
        "input1=preprocess(email_1)\n",
        "input2=preprocess(email_2)\n",
        "input3=preprocess(email_3)\n",
        "input= input1+input2+input3\n",
        "summarised_text, sorted_freqs = generate_summary(input,5)\n",
        "summarised_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"In case you experience any further problems with the app, please don't hesitate to contact me again.Thanks for the advertisement you sent me about the Fashion Show.\",\n",
              " 'I think it will be a fantastic event and I want to be there, but before I come to Paris I need to know a little more about train timetables and the show.',\n",
              " 'I think the best option is to take the last one from Berlin, but it doesn’t arrive in Paris until about ten o’clock.',\n",
              " 'Do they say it is going to rain within the next 2 days or not?',\n",
              " 'I’m sorry that I didn’t reply to your letter sooner, but I’m spending my time now in a summer house where Internet connection is very weak.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    }
  ]
}